import json, requests, os, subprocess, csv, glob, time

def get_git_info():
    try:
        rev = subprocess.check_output(['git', 'rev-parse', '--short', 'HEAD']).decode('ascii').strip()
        return rev
    except:
        return "unknown"

def check_server_health(target_host, max_retries=10, retry_delay=3):
    """ì„œë²„ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°"""
    
    print(f"ğŸ¥ ì„œë²„ í—¬ìŠ¤ ì²´í¬ ì‹œì‘: {target_host}")
    
    for i in range(max_retries):
        try:
            # ê°„ë‹¨í•œ ì—”ë“œí¬ì¸íŠ¸ë¡œ ì„œë²„ í™•ì¸
            response = requests.get(f"{target_host}/text/all", timeout=5)
            if response.status_code == 200:
                print(f"âœ… ì„œë²„ ì¤€ë¹„ ì™„ë£Œ! ({i+1}ë²ˆì§¸ ì‹œë„)")
                return True
        except Exception as e:
            print(f"â³ ì„œë²„ ëŒ€ê¸° ì¤‘... ({i+1}/{max_retries}) - {str(e)[:50]}")
            if i < max_retries - 1:
                time.sleep(retry_delay)
    
    print(f"âŒ ì„œë²„ê°€ {max_retries * retry_delay}ì´ˆ ë‚´ì— ì‘ë‹µí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return False

def run_commands():
    target_host = os.getenv("TARGET_HOST", "http://localhost:5000")
    print(f"ğŸ¬ [DEBUG] í…ŒìŠ¤íŠ¸ ë° ë¶€í•˜ ì¸¡ì • ì‹œì‘ (ëª©ì ì§€: {target_host})")
    
    # 1. Pytest ì‹¤í–‰ (ê²°ê³¼ íŒŒì¼ì´ ì—†ì„ ë•Œë§Œ ì‹¤í–‰)
    if not os.path.exists("result.json"):
        print(f"ğŸ§ª 1. Pytest ì‹¤í–‰ ì¤‘...")
        subprocess.run(["pytest", "--json-report", "--json-report-file=result.json"], check=True)
    
    # 1.5. ì„œë²„ í—¬ìŠ¤ ì²´í¬ (ë¶€í•˜í…ŒìŠ¤íŠ¸ ì „ì— ì„œë²„ê°€ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸)
    if not check_server_health(target_host):
        print("âš ï¸ ì„œë²„ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ì§€ë§Œ ë¶€í•˜í…ŒìŠ¤íŠ¸ë¥¼ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
    
    # 2. Locust ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print(f"ğŸš€ 2. Locust ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
    result = subprocess.run([
        "locust", 
        "-f", "tests/load/locustfile.py",
        "--headless", 
        "-u", "30", 
        "-r", "5", 
        "--run-time", "20s",
        "--csv", "perf",
        "--host", target_host
    ], check=False, capture_output=True, text=True)  # check=Falseë¡œ ë³€ê²½í•˜ì—¬ ì—ëŸ¬ ìƒì„¸ í™•ì¸
    
    # Locust ì‹¤í–‰ ê²°ê³¼ í™•ì¸
    print(f"ğŸ“Š Locust ì‹¤í–‰ ì™„ë£Œ (exit code: {result.returncode})")
    if result.stdout:
        print(f"ğŸ“ Locust stdout ì „ì²´:\n{result.stdout}")
    if result.stderr:
        print(f"âš ï¸ Locust stderr:\n{result.stderr}")
    
    # Locust ì‹¤íŒ¨ ì‹œ ìƒì„¸ ì—ëŸ¬ ì¶œë ¥
    if result.returncode != 0:
        print(f"âŒ Locust ì‹¤í–‰ ì‹¤íŒ¨ (exit code: {result.returncode})")
        if result.stderr:
            print(f"ğŸ” ìƒì„¸ ì—ëŸ¬ ë©”ì‹œì§€:\n{result.stderr}")
        raise Exception(f"Locust ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {result.stderr or 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}")
    
    # ìƒì„±ëœ CSV íŒŒì¼ í™•ì¸
    import glob
    csv_files = glob.glob("perf_*.csv")
    print(f"ğŸ“ ìƒì„±ëœ CSV íŒŒì¼: {csv_files}")
    for csv_file in csv_files:
        if os.path.exists(csv_file):
            size = os.path.getsize(csv_file)
            print(f"   - {csv_file}: {size} bytes")

def send_combined_report():
    print("ğŸ“¡ [DEBUG] ë¦¬í¬íŠ¸ ë°ì´í„° ì·¨í•© ë° ì „ì†¡ ì¤€ë¹„ ì¤‘...")
    git_hash = get_git_info()
    
    if not os.path.exists("result.json"):
        print("âŒ [WARNING] result.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì „ì†¡ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return

    with open("result.json", "r", encoding="utf-8") as f:
        test_data = json.load(f)
    
    perf_results = []
    csv_file_path = "perf_stats.csv"
    
    print(f"ğŸ” CSV íŒŒì¼ í™•ì¸: {csv_file_path}")
    if os.path.exists(csv_file_path):
        file_size = os.path.getsize(csv_file_path)
        print(f"âœ… CSV íŒŒì¼ ì¡´ì¬: {file_size} bytes")
        
        with open(csv_file_path, "r", encoding="utf-8") as f:
            content = f.read()
            print(f"ğŸ“„ CSV íŒŒì¼ ë‚´ìš© (ì²˜ìŒ 500ì):\n{content[:500]}")
            
            f.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
            reader = csv.DictReader(f)
            rows = list(reader)
            print(f"ğŸ“Š CSV í–‰ ìˆ˜: {len(rows)}")
            
            # ëœë¤ limit API ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ í‰ê·  ê³„ì‚°
            main_random_data = []
            
            for row in rows:
                print(f"   - í–‰ ë°ì´í„°: {dict(row)}")
                if row.get('Name') and row['Name'] != 'Aggregated':
                    try:
                        total_req = int(row.get('Request Count', 0) or 0)
                        fail_count = int(row.get('Failure Count', 0) or 0)
                        
                        endpoint_name = row['Name']
                        
                        # ëœë¤ limit APIì¸ì§€ í™•ì¸
                        if '/text/main/' in endpoint_name or endpoint_name == '/text/main/[limit]':
                            # ëœë¤ limit API ë°ì´í„° ìˆ˜ì§‘ (ë‚˜ì¤‘ì— í‰ê·  ê³„ì‚°)
                            main_random_data.append({
                                "total_req": total_req,
                                "fail_count": fail_count,
                                "avg_latency": float(row.get('Average Response Time', 0) or 0),
                                "p95_latency": float(row.get('95%', 0) or 0) if row.get('95%', 'N/A') != 'N/A' else 0,
                                "p99_latency": float(row.get('99%', 0) or 0) if row.get('99%', 'N/A') != 'N/A' else 0,
                                "max_latency": float(row.get('Max Response Time', 0) or 0),
                                "rps": float(row.get('Requests/s', 0) or 0),
                            })
                        else:
                            # ì¼ë°˜ APIëŠ” ê·¸ëŒ€ë¡œ ì¶”ê°€
                            perf_results.append({
                                "method": row.get('Type', 'GET'),
                                "endpoint": endpoint_name,
                                "avg_latency": float(row.get('Average Response Time', 0) or 0),
                                "p95_latency": float(row.get('95%', 0) or 0) if row.get('95%', 'N/A') != 'N/A' else 0,
                                "p99_latency": float(row.get('99%', 0) or 0) if row.get('99%', 'N/A') != 'N/A' else 0,
                                "max_latency": float(row.get('Max Response Time', 0) or 0),
                                "rps": float(row.get('Requests/s', 0) or 0),
                                "total_requests": total_req,
                                "fail_count": fail_count,
                                "error_rate": round((fail_count / total_req * 100), 2) if total_req > 0 else 0
                            })
                    except (ValueError, KeyError) as e:
                        print(f"âš ï¸ CSV íŒŒì‹± ì¤‘ ê±´ë„ˆëœ€: {e}, í–‰: {row}")
                        continue
            
            # ëœë¤ limit API í‰ê·  ê³„ì‚°
            if main_random_data:
                total_req_sum = sum(d['total_req'] for d in main_random_data)
                fail_count_sum = sum(d['fail_count'] for d in main_random_data)
                
                # ê°€ì¤‘ í‰ê·  ê³„ì‚° (ìš”ì²­ ìˆ˜ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©)
                if total_req_sum > 0:
                    weighted_avg_latency = sum(d['avg_latency'] * d['total_req'] for d in main_random_data) / total_req_sum
                    weighted_avg_p95 = sum(d['p95_latency'] * d['total_req'] for d in main_random_data if d['p95_latency'] > 0) / sum(d['total_req'] for d in main_random_data if d['p95_latency'] > 0) if any(d['p95_latency'] > 0 for d in main_random_data) else 0
                    weighted_avg_p99 = sum(d['p99_latency'] * d['total_req'] for d in main_random_data if d['p99_latency'] > 0) / sum(d['total_req'] for d in main_random_data if d['p99_latency'] > 0) if any(d['p99_latency'] > 0 for d in main_random_data) else 0
                    max_latency = max(d['max_latency'] for d in main_random_data)
                    total_rps = sum(d['rps'] for d in main_random_data)
                else:
                    weighted_avg_latency = 0
                    weighted_avg_p95 = 0
                    weighted_avg_p99 = 0
                    max_latency = 0
                    total_rps = 0
                
                perf_results.append({
                    "method": "GET",
                    "endpoint": "/text/main/[limit]",
                    "avg_latency": round(weighted_avg_latency, 2),
                    "p95_latency": round(weighted_avg_p95, 2),
                    "p99_latency": round(weighted_avg_p99, 2),
                    "max_latency": round(max_latency, 2),
                    "rps": round(total_rps, 2),
                    "total_requests": total_req_sum,
                    "fail_count": fail_count_sum,
                    "error_rate": round((fail_count_sum / total_req_sum * 100), 2) if total_req_sum > 0 else 0
                })
                print(f"ğŸ“Š ëœë¤ limit API í†µí•© ì™„ë£Œ: {len(main_random_data)}ê°œ ë°ì´í„°ë¥¼ í‰ê· í™”")
    else:
        print(f"âŒ CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_file_path}")
        # ë‹¤ë¥¸ ê°€ëŠ¥í•œ íŒŒì¼ëª… í™•ì¸
        import glob
        all_csv = glob.glob("perf*.csv")
        print(f"ğŸ” ë‹¤ë¥¸ CSV íŒŒì¼ë“¤: {all_csv}")
    
    print(f"ğŸ“ˆ ìˆ˜ì§‘ëœ ì„±ëŠ¥ ë°ì´í„°: {len(perf_results)}ê°œ")

    payload = {
        "git_commit": git_hash,
        "total": test_data.get("summary", {}).get("total", 0),
        "passed": test_data.get("summary", {}).get("passed", 0),
        "failed": test_data.get("summary", {}).get("failed", 0),
        "user_count": 50,
        "pytest_results": [
            {
                "test_name": t['nodeid'].split("::")[-1],
                "status": t['outcome'],
                "message": t.get('call', {}).get('longrepr', "") if t['outcome'] == 'failed' else ""
            } for t in test_data.get("tests", [])
        ],
        "perf_results": perf_results
    }

    base_url = os.getenv("SERVER_URL", "http://localhost:5000")
    target_url = f"{base_url}/admin/report"
    print(f"ğŸ“¤ [DEBUG] ì „ì†¡ ëª©ì ì§€: {target_url}")

    print("-" * 50)
    print(f"ğŸš€ [REAL-TIME CHECK] ì „ì†¡ ì‹œì‘!")
    print(f"ğŸ“ ëª©ì ì§€ ì£¼ì†Œ: {target_url}")
    print(f"ğŸ“¦ ë°ì´í„° í¬ê¸°: {len(json.dumps(payload))} bytes")
    print(f"ğŸ”‘ í™˜ê²½ë³€ìˆ˜ SERVER_URL ìƒíƒœ: {os.getenv('SERVER_URL')}")
    print("-" * 50)

    
    try:
        response = requests.post(target_url, json=payload, timeout=20)
        print(f"âœ… ë¦¬í¬íŠ¸ ì „ì†¡ ê²°ê³¼: {response.status_code}")
        print(f"ğŸ“ ì„œë²„ ì‘ë‹µ: {response.text}")
    except Exception as e:
        print(f"âŒ ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {e}")

def cleanup_files():
    print("ğŸ§¹ [DEBUG] ì„ì‹œ ê²°ê³¼ íŒŒì¼ ì •ë¦¬ ì¤‘...")
    for f in glob.glob("perf_*"):
        try: os.remove(f)
        except: pass
    if os.path.exists("result.json"):
        try: os.remove("result.json")
        except: pass

# ğŸ”¥ ê°€ì¥ ì¤‘ìš”í•œ ì‹¤í–‰ë¬¸ ë¸”ë¡!
if __name__ == "__main__":
    print("ğŸ ìŠ¤í¬ë¦½íŠ¸ ê°€ë™ ì‹œì‘")
    try:
        run_commands()           # 1. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° íŒŒì¼ ìƒì„±
        send_combined_report()    # 2. ê²°ê³¼ ì „ì†¡
        cleanup_files()           # 3. ì •ë¦¬
        print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ")
    except Exception as e:
        print(f"ğŸ§¨ [FATAL] ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")